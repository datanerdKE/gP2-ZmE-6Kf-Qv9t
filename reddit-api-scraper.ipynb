{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8496240,"sourceType":"datasetVersion","datasetId":5069712}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Google Cloud BigQuery\nfrom google.cloud import bigquery\n\n# Reddit API\nimport praw\nimport requests\n\n# Data Manipulation & Exploration\nimport pandas as pd\nimport datetime\nimport time\n\n# Access Credentials\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-28T13:44:23.759946Z","iopub.execute_input":"2024-05-28T13:44:23.760320Z","iopub.status.idle":"2024-05-28T13:44:29.863113Z","shell.execute_reply.started":"2024-05-28T13:44:23.760284Z","shell.execute_reply":"2024-05-28T13:44:29.861821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Client Object\nclient = bigquery.Client()","metadata":{"execution":{"iopub.status.busy":"2024-05-28T13:44:29.864847Z","iopub.execute_input":"2024-05-28T13:44:29.865681Z","iopub.status.idle":"2024-05-28T13:44:29.871274Z","shell.execute_reply.started":"2024-05-28T13:44:29.865644Z","shell.execute_reply":"2024-05-28T13:44:29.869997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Path to Reddit API Credentials\ncredentials = 'client_secrets.json'\n\n# Read Credentials from JSON file\nwith open(credentials) as f:\n    creds = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T13:44:29.874753Z","iopub.execute_input":"2024-05-28T13:44:29.875352Z","iopub.status.idle":"2024-05-28T13:44:29.896887Z","shell.execute_reply.started":"2024-05-28T13:44:29.875292Z","shell.execute_reply":"2024-05-28T13:44:29.895633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Python Reddit API Wrapper\nreddit = praw.Reddit(client_id=creds['client_id'],\n                     client_secret=creds['client_secret'],\n                     user_agent=creds['user_agent'],\n                     redirect_uri=creds['redirect_uri'],\n                     refresh_token=creds['refresh_token'])","metadata":{"execution":{"iopub.status.busy":"2024-05-28T13:44:29.898419Z","iopub.execute_input":"2024-05-28T13:44:29.898838Z","iopub.status.idle":"2024-05-28T13:44:30.093074Z","shell.execute_reply.started":"2024-05-28T13:44:29.898803Z","shell.execute_reply":"2024-05-28T13:44:30.091595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an Empty DataFrame for Result Storage\nbigdata = pd.DataFrame()\n\n# Provide List of Different Genres\ngenres = ['new','hot','rising','top']\n\n# Define Search Parameter\nsearch = reddit.subreddit('Kenya')\n\n# Loop through Genres while Extracting Posts\nfor genre in genres:\n    posts = []\n    for post in getattr(search, genre)(limit=1000):\n        created_at_datetime = datetime.datetime.fromtimestamp(post.created)\n        today_date = datetime.datetime.today()\n        genr = genre\n        posts.append([genr, post.title, post.score, post.id, post.subreddit, post.url, \n                    post.num_comments, post.selftext, created_at_datetime, today_date, search.subscribers\n                    ])\n    data = pd.DataFrame(\n        posts,\n        columns=[\n            'genre', 'title', 'score', 'id', 'subreddit', 'url', 'num_comments', \n            'body', 'created', 'today_date','subscribers'\n                ])\n    \n    # Concatenate \n    bigdata = pd.concat([bigdata,data],ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T13:44:30.095143Z","iopub.execute_input":"2024-05-28T13:44:30.095535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Table Id\ntable_id = 'project-adrian-julius-aluoch.cronjobs.reddit_kenya'\n\n# Load Extracted Data into BigQuery\njob = client.load_table_from_dataframe(data,table_id)\nwhile job.state != 'DONE':\n    time.sleep(4)\n    job.reload()\n    print(job.state)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define SQL Query to Retrieve All Records from BigQuery\nsql = (\n    'SELECT *'\n    'FROM `cronjobs.reddit_kenya`'\n      )\n\n# Run SQL Query\ndata = client.query(sql).to_dataframe()\n\n# Drop Duplicated Records\ndata.drop_duplicates(subset=['title'],inplace=True)\n\n# Replace Original BigQuery Table \nclient.delete_table(table_id)\n\n# Upload New BigQuery Table\njob = client.load_table_from_dataframe(data,table_id)\nwhile job.state != 'DONE':\n    time.sleep(1)\n    job.reload()\n    print(job.state)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}