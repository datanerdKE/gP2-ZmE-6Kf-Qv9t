{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-28T13:44:23.760320Z","iopub.status.busy":"2024-05-28T13:44:23.759946Z","iopub.status.idle":"2024-05-28T13:44:29.863113Z","shell.execute_reply":"2024-05-28T13:44:29.861821Z","shell.execute_reply.started":"2024-05-28T13:44:23.760284Z"},"trusted":true},"outputs":[],"source":["# Google Cloud BigQuery\n","from google.cloud import bigquery\n","\n","# Reddit API\n","import praw\n","import requests\n","\n","# Data Manipulation & Exploration\n","import pandas as pd\n","import datetime\n","import time\n","\n","# Access Credentials\n","import json\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T13:44:29.865681Z","iopub.status.busy":"2024-05-28T13:44:29.864847Z","iopub.status.idle":"2024-05-28T13:44:29.871274Z","shell.execute_reply":"2024-05-28T13:44:29.869997Z","shell.execute_reply.started":"2024-05-28T13:44:29.865644Z"},"trusted":true},"outputs":[],"source":["# Initialize Client Object\n","client = bigquery.Client()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T13:44:29.875352Z","iopub.status.busy":"2024-05-28T13:44:29.874753Z","iopub.status.idle":"2024-05-28T13:44:29.896887Z","shell.execute_reply":"2024-05-28T13:44:29.895633Z","shell.execute_reply.started":"2024-05-28T13:44:29.875292Z"},"trusted":true},"outputs":[],"source":["# Path to Reddit API Credentials\n","credentials = 'client_secrets.json'\n","\n","# Read Credentials from JSON file\n","with open(credentials) as f:\n","    creds = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T13:44:29.898838Z","iopub.status.busy":"2024-05-28T13:44:29.898419Z","iopub.status.idle":"2024-05-28T13:44:30.093074Z","shell.execute_reply":"2024-05-28T13:44:30.091595Z","shell.execute_reply.started":"2024-05-28T13:44:29.898803Z"},"trusted":true},"outputs":[],"source":["# Python Reddit API Wrapper\n","reddit = praw.Reddit(client_id=creds['client_id'],\n","                     client_secret=creds['client_secret'],\n","                     user_agent=creds['user_agent'],\n","                     redirect_uri=creds['redirect_uri'],\n","                     refresh_token=creds['refresh_token'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T13:44:30.095535Z","iopub.status.busy":"2024-05-28T13:44:30.095143Z"},"trusted":true},"outputs":[],"source":["# Create an Empty DataFrame for Result Storage\n","bigdata = pd.DataFrame()\n","\n","# Provide List of Different Genres\n","genres = ['new','hot','rising','top']\n","\n","# Define Search Parameter\n","search = reddit.subreddit('Kenya')\n","\n","# Loop through Genres while Extracting Posts\n","for genre in genres:\n","    posts = []\n","    for post in getattr(search, genre)(limit=1000):\n","        created_at_datetime = datetime.datetime.fromtimestamp(post.created)\n","        today_date = datetime.datetime.today()\n","        genr = genre\n","        posts.append([genr, post.title, post.score, post.id, post.subreddit, post.url, \n","                    post.num_comments, post.selftext, created_at_datetime, today_date, search.subscribers\n","                    ])\n","    data = pd.DataFrame(\n","        posts,\n","        columns=[\n","            'genre', 'title', 'score', 'id', 'subreddit', 'url', 'num_comments', \n","            'body', 'created', 'today_date','subscribers'\n","                ])\n","    \n","    # Concatenate \n","    bigdata = pd.concat([bigdata,data],ignore_index=True)\n","\n","bigdata.to_csv('reddit.csv',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Import Data from CSV\n","data = pd.read_csv('reddit.csv')\n","\n","# Define Table Id\n","table_id = 'project-adrian-julius-aluoch.cronjobs.reddit_kenya'\n","\n","# Load Extracted Data into BigQuery\n","job = client.load_table_from_dataframe(data,table_id)\n","while job.state != 'DONE':\n","    time.sleep(4)\n","    job.reload()\n","    print(job.state)\n","\n","# Delete CSV file\n","os.remove('reddit.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define SQL Query to Retrieve All Records from BigQuery\n","sql = (\n","    'SELECT *'\n","    'FROM `cronjobs.reddit_kenya`'\n","      )\n","\n","# Run SQL Query\n","data = client.query(sql).to_dataframe()\n","\n","# Drop Duplicated Records\n","data.drop_duplicates(subset=['title'],inplace=True)\n","\n","# Replace Original BigQuery Table \n","client.delete_table(table_id)\n","\n","# Upload New BigQuery Table\n","job = client.load_table_from_dataframe(data,table_id)\n","while job.state != 'DONE':\n","    time.sleep(1)\n","    job.reload()\n","    print(job.state)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5069712,"sourceId":8496240,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
